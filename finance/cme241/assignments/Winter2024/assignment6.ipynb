{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stanford CME 241 (Winter 2024) - Assignment 6\n",
    "\n",
    "**Due: Feb 19 @ 11:59pm Pacific Time on Gradescope.**\n",
    "\n",
    "Assignment instructions:\n",
    "- **Solve all 3 questions.**\n",
    "- Empty code blocks are for your use. Feel free to create more under each section as needed.\n",
    "\n",
    "Submission instructions:\n",
    "- When complete, fill out your publicly available GitHub repo file URL and group members below, then export or print this .ipynb file to PDF and upload the PDF to Gradescope.\n",
    "\n",
    "*Link to this ipynb file in your public GitHub repo (replace below URL with yours):* \n",
    "\n",
    "https://github.com/my-username/my-repo/assignment-file-name.ipynb\n",
    "\n",
    "*Group members (replace below names with people in your group):* \n",
    "- Person 1\n",
    "- Person 2\n",
    "- Person 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "We consider a special case of the Optimal Market-Making problem we\n",
    "covered in class (Avellandea-Stoikov formulation) where the market-maker\n",
    "has a cash amount of $W \\in \\mathbb{R}$ at time 0 and an inventory of\n",
    "shares equal to $I \\in \\mathbb{Z}$ (note: this could be positive or\n",
    "negative), but is not going to be market-making until time $T$. The\n",
    "market maker's *Value Function* at time $t$ (with $0 \\leq t \\leq T$) is\n",
    "given by the Expected Utility at time $T$ (conditional on the time $t$\n",
    "and the OB Mid Price $S_t$ at time $t$):\n",
    "\n",
    "$$V(t, S_t, W, I) = \\mathbb{E}[-e^{-\\gamma \\cdot (W + I \\cdot S_T)} | (t, S_t)]$$\n",
    "\n",
    "Assume the same process for the OB Mid Price as we had covered in class:\n",
    "\n",
    "$$dS_t = \\sigma \\cdot dz_t$$\n",
    "\n",
    "for some fixed $\\sigma \\in \\mathbb{R}^+$. This means:\n",
    "\n",
    "$$S_{t_2} \\sim \\mathcal{N}(S_{t_1}, \\sigma^2 \\cdot (t_2 - t_1))$$\n",
    "\n",
    "for all $0 \\leq t_1 \\leq t_2$.\n",
    "\n",
    "-   Under this process for $S_t$, evaluate the conditional expectation\n",
    "    $\\mathbb{E}[-e^{-\\gamma \\cdot (W + I \\cdot S_T)} | (t, S_t)]$ so you\n",
    "    have a simple expression for $V(t, S_t, W, I)$.\n",
    "\n",
    "-   Using the above expression for $V(t, S_t, W, I)$, calculate the\n",
    "    Indifference Bid Price $Q^{(b)}(t, S_t, I)$ and the Indifference Ask\n",
    "    Price $Q^{(a)}(t,S_t,I)$, which have the same definitions as we had\n",
    "    covered in class, as follows:\n",
    "\n",
    "    $$V(t,S_t,W - Q^{(b)}(t, S_t, I), I + 1) = V(t,S_t,W, I)$$\n",
    "    $$V(t,S_t,W + Q^{(a)}(t, S_t, I), I - 1) = V(t,S_t,W, I)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "We'd like to test the performance of the Optimal Policy we derived in\n",
    "class for the Optimal Market-Making problem. In particular, we want to\n",
    "compare this Optimal Policy against a policy (call it \"Naive Policy\")\n",
    "that is always symmetric around the OB Mid Price (rather than around the\n",
    "Indifference Price) with a constant Bid-Ask Spread equal to the average\n",
    "Bid-Ask Spread of the Optimal Policy.\n",
    "\n",
    "We will do the comparison by generating a large number of simulation\n",
    "traces. Each simulation trace consists of $\\frac T {\\Delta t}$ time\n",
    "steps. The time step $\\Delta t$ needs to be small enough so that the\n",
    "probability of multiple orders transacting with the market-maker is\n",
    "small but needs to be large enough so that there are indeed orders that\n",
    "transact with the market-maker. In their paper, Avallaneda-Stoikov point\n",
    "out that $\\Delta t = 0.005$ worked well in their simulation experiments.\n",
    "\n",
    "Here are the details on how to perform a time step in each simulation\n",
    "trace for the Optimal Policy:\n",
    "\n",
    "-   At each time $t$, we observe the *State*, and calculate the Optimal\n",
    "    Action $(P_t^{(b)^*}, P_t^{(a)^*})$.\n",
    "\n",
    "-   With probability\n",
    "    $c \\cdot e^{-k \\cdot \\delta_t^{(a)^*}} \\cdot \\Delta t$, the\n",
    "    inventory variable is decremented by 1 and the trading PnL is\n",
    "    increased by $P_t^{(a)^*}$.\n",
    "\n",
    "-   With probability\n",
    "    $c \\cdot e^{-k \\cdot \\delta_t^{(b)^*}} \\cdot \\Delta t$, the\n",
    "    inventory variable is incremented by 1 and the trading PnL is\n",
    "    decreased by $P_t^{(b)^*}$.\n",
    "\n",
    "-   The OB Mid Price is incremented or decremented randomly (each with\n",
    "    probability 0.5) by $\\sigma \\cdot \\sqrt{\\Delta t}$.\n",
    "\n",
    "-   These updates to the inventory variable, to the trading PnL and to\n",
    "    the OB Mid Price give us the *State* for the next time\n",
    "    $t + \\Delta t$.\n",
    "\n",
    "We run a large number (say 10,000) such simulation traces. We calculate\n",
    "the average Bid-Ask Spread across all time steps across all simulation\n",
    "traces. Then we set the Bid-Ask Spread for the \"naive policy\" to be this\n",
    "average Bid-Ask Spread (constant Bid-Ask Spread). Repeat the same large\n",
    "number of simulations for the \"naive policy\".\n",
    "\n",
    "Track the relevant metrics for each simulation trace on both the\n",
    "policies - the trading PnL, the Inventory, the OB Mid Price, the Bid\n",
    "Price, the Ask Price, the number of hits and lifts etc. Plot graphs for\n",
    "these metrics. You can view the metrics on a single simulation trace or\n",
    "you can view the average metrics at a fixed time (in particular for\n",
    "terminal time $T$). Demonstrate empirically that the Optimal Policy does\n",
    "indeed perform better than the \"naive policy\".\n",
    "\n",
    "Avallaneda-Stoikov used the following parameters in their simulation:\n",
    "\n",
    "$S_0 = 100, T = 1, \\Delta t = 0.005, \\gamma = 0.1, \\sigma = 2, I_0 = 0, k = 1.5, c = 140$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Although the provided code contains a number of utilties for Monte-Carlo\n",
    "prediction, you may consider writing re-writing these functions to\n",
    "improve your understanding.\n",
    "\n",
    "1.  We have written the function `mc_prediction` in\n",
    "    [rl/monte_carlo.py](https://github.com/TikhonJelvis/RL-book/blob/master/rl/monte_carlo.py)\n",
    "    as an implementation of Monte-Carlo Prediction with function\n",
    "    approximation. You have also learnt that since Tabular MC Prediction\n",
    "    is a special case of MC Prediction with Function Approximation and\n",
    "    so, writing a separate function for Tabular MC Prediction is not\n",
    "    necessary. But for a learning experience, it's a great idea to write\n",
    "    a function for Tabular MC Prediction **from scratch**. Think about\n",
    "    what the input and output types must be. Be sure to reduce the\n",
    "    learning rate appropriately as a function of number of updates (or\n",
    "    as a function of number of episodes).\n",
    "\n",
    "2.  We have written the function `td_prediction` in\n",
    "    [rl/td.py](https://github.com/TikhonJelvis/RL-book/blob/master/rl/td.py)\n",
    "    as an implementation of Temporal-Difference Prediction with function\n",
    "    approximation. You have also learnt that since Tabular TD Prediction\n",
    "    is a special case of TD Prediction with Function Approximation and\n",
    "    so, writing a separate function for Tabular TD Prediction is not\n",
    "    necessary. But for a learning experience, it's a great idea to write\n",
    "    a function for Tabular TD Prediction **from scratch**. Think about\n",
    "    what the input and output types must be. Be sure to reduce the\n",
    "    learning rate appropriately as a function of number of updates.\n",
    "\n",
    "3.  Test your above implementations of Tabular MC Prediction and Tabular\n",
    "    TD Prediction on\\\n",
    "    `SimpleInventoryMRPFinite` (from\n",
    "    [rl/chapter2/simple_inventory_mrp.py](https://github.com/TikhonJelvis/RL-book/blob/master/rl/chapter2/simple_inventory_mrp.py))\n",
    "    by ensuring that your Value Function output matches that produced by\n",
    "    the function approximation versions of MC Prediction and TD\n",
    "    Prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
