\documentclass[12pt]{exam}
\usepackage[utf8]{inputenc}
\usepackage{graphicx} % Allows including images
\usepackage{cool}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{pseudocode}
\usepackage[colorlinks = true,
            linkcolor = blue,
            urlcolor  = blue,
            citecolor = blue,
            anchorcolor = blue]{hyperref}
\usepackage{MnSymbol,wasysym}
\usepackage{geometry} % see geometry.pdf on how to lay out the page. There's lots.
\geometry{a4paper} 
\newgeometry{vmargin={20mm}, hmargin={14mm,18mm}}
 
 \lstset{language=Python,keywordstyle={\bfseries \color{blue}}}
 
\begin{document}
\begin{center}
{\large {\bf Stanford CME 241 (Winter 2022) - Assignment 2}}
\end{center}
 
{\large{\bf Assignments:}}
\begin{questions}
\question Model the game of \href{https://toytheater.com/snakes-and-ladders/}{Snakes and Ladders} (single-player game) as a Markov Process. Write out it's state space and structure of transition probabilities.
\question Create a \lstinline{transition_map: Transition} data structure to represent the transition probabilities of the Snakes and Ladders Markov Process so you can model the game as an instance of \lstinline{FiniteMarkovProcess}. Use the method \lstinline{traces} to create sampling traces. Plot a graph of the probability distribution of time steps to finish the game.
\question Solve this \href{https://www.youtube.com/watch?v=ZLTyX4zL2Fc}{Frog Puzzle} (watch only the first 3 minutes of this YouTube video) using what you have learnt about Markov Processes so far.
\question For the Snakes and Ladders game, we are interested in calculating the expected number of dice rolls to finish the game. In order to calculate this, extend the Snakes and Ladders FiniteMarkovProcess to an appropriate FiniteMarkovRewardProcess instance. What should be the Rewards model in this MRP so you can use one of the methods in the FiniteMarkovRewardProcess class to determine the expected number of dice rolls to finish the game?
\question {\bf Optional} Extend one of the Stock Price examples in Chapter 1 to be a Markov Reward Process by defining a Reward $R_t$ that is a function $f$ of the Stock price $X_t$ at each time $t$. Program it as a class that implements the interface of the \lstinline{@abstractclass MarkovRewardProcess} and allow flexibility in specifying your own function $f$. This is an infinite-states, non-terminating MRP. Compute it's Value Function for any discount factor $0 \leq \gamma < 1$.
\end{questions}

\end{document}